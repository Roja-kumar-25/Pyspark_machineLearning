{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 09:47:50 WARN Utils: Your hostname, AI-CJB-LAP-459 resolves to a loopback address: 127.0.1.1; using 192.168.1.164 instead (on interface wlp0s20f3)\n",
      "24/09/27 09:47:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/27 09:47:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"LinearRegression.com\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE DATASET(\"BOSTON HOUSING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 10:10:28 WARN SparkContext: The path https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv has been added already. Overwriting of added paths is not supported in the current version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|crim   |zn  |indus|chas|nox  |rm   |age  |dis   |rad|tax|ptratio|b     |lstat|medv|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|18.0|2.31 |0   |0.538|6.575|65.2 |4.09  |1  |296|15.3   |396.9 |4.98 |24.0|\n",
      "|0.02731|0.0 |7.07 |0   |0.469|6.421|78.9 |4.9671|2  |242|17.8   |396.9 |9.14 |21.6|\n",
      "|0.02729|0.0 |7.07 |0   |0.469|7.185|61.1 |4.9671|2  |242|17.8   |392.83|4.03 |34.7|\n",
      "|0.03237|0.0 |2.18 |0   |0.458|6.998|45.8 |6.0622|3  |222|18.7   |394.63|2.94 |33.4|\n",
      "|0.06905|0.0 |2.18 |0   |0.458|7.147|54.2 |6.0622|3  |222|18.7   |396.9 |5.33 |36.2|\n",
      "|0.02985|0.0 |2.18 |0   |0.458|6.43 |58.7 |6.0622|3  |222|18.7   |394.12|5.21 |28.7|\n",
      "|0.08829|12.5|7.87 |0   |0.524|6.012|66.6 |5.5605|5  |311|15.2   |395.6 |12.43|22.9|\n",
      "|0.14455|12.5|7.87 |0   |0.524|6.172|96.1 |5.9505|5  |311|15.2   |396.9 |19.15|27.1|\n",
      "|0.21124|12.5|7.87 |0   |0.524|5.631|100.0|6.0821|5  |311|15.2   |386.63|29.93|16.5|\n",
      "|0.17004|12.5|7.87 |0   |0.524|6.004|85.9 |6.5921|5  |311|15.2   |386.71|17.1 |18.9|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url=\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "boston_df= spark.read.csv(SparkFiles.get(\"BostonHousing.csv\"),header=True, inferSchema=True)\n",
    "boston_df.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"crim\", \"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "boston_df = assembler.transform(boston_df)\n",
    "final_data = boston_df.select(\"features\", \"medv\")\n",
    "\n",
    "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD LINEAR REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 10:13:21 WARN Instrumentation: [6e91d186] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/09/27 10:13:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "lr=LinearRegression(featuresCol=\"features\",labelCol=\"medv\",predictionCol=\"predicted_mdev\")\n",
    "lr_model=lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE PREDICTIONS AND EVALUATE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 4.671806485171284\n",
      "R-squared(R2) on test data :0.793152\n"
     ]
    }
   ],
   "source": [
    "predictions=lr_model.transform(test_data)\n",
    "\n",
    "evaluator=RegressionEvaluator(labelCol=\"medv\",predictionCol=\"predicted_mdev\",metricName='rmse')\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error:\",rmse)\n",
    "\n",
    "evaluator2=RegressionEvaluator(labelCol=\"medv\",predictionCol=\"predicted_mdev\",metricName=\"r2\")\n",
    "r2=evaluator2.evaluate(predictions)\n",
    "print(\"R-squared(R2) on test data :{:3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSPECT THE MODEL COEFFICIENTS AND INTERCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients : [-0.11362203729408954,0.048909186934053925,0.02379542898673389,2.801771998735119,-18.4154245411894,3.5158797633120065,0.0052116821614709204,-1.4163830723539739,0.3317669315937035,-0.013607893704163878,-0.9534143338408072,0.008602677392853256,-0.519503531247664]\n",
      "Intercept : 38.61699144573437\n"
     ]
    }
   ],
   "source": [
    "coeff=lr_model.coefficients\n",
    "intercepts=lr_model.intercept\n",
    "print(\"Coefficients :\",coeff)\n",
    "print(\"Intercept :\",intercepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYZE THE FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "  nox: 18.415\n",
      "  rm: 3.516\n",
      "  chas: 2.802\n",
      "  dis: 1.416\n",
      "  ptratio: 0.953\n",
      "  lstat: 0.520\n",
      "  rad: 0.332\n",
      "  crim: 0.114\n",
      "  zn: 0.049\n",
      "  indus: 0.024\n",
      "  tax: 0.014\n",
      "  b: 0.009\n",
      "  age: 0.005\n"
     ]
    }
   ],
   "source": [
    "feature_importance = sorted(list(zip(boston_df.columns[:-1], map(abs, coeff))), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in feature_importance:\n",
    "    print(\"  {}: {:.3f}\".format(feature, importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE AND LOAD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "lr_model.save(\"lr_model\")\n",
    "\n",
    "# Load the model\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "loaded_model = LinearRegressionModel.load(\"lr_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
